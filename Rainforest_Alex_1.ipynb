{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draft 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/NeuralNetworks/keras_tf/lib/python3.4/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Imports complete-----\n"
     ]
    }
   ],
   "source": [
    "#XGB / FRACTALS Imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import xgboost as xgb\n",
    "import pickle as pickle\n",
    "import os.path\n",
    "import cv2\n",
    "from skimage import io\n",
    "import datetime as dt\n",
    "\n",
    "import scipy\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "from PIL import Image, ImageStat\n",
    "print(\"------Imports complete-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Fan Fei / KERAS Imports\n",
    "\n",
    "# Tips on using pre-trained model in Keras\n",
    "# http://stackoverflow.com/questions/41764041/fine-tuning-pretrained-model-in-keras/41791568\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# Furter import to allow for re-training / fine-tuning\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Paths Built-----\n"
     ]
    }
   ],
   "source": [
    "random_seed = 0\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "train_path = \"/media/alex/B44254FE4254C730/Users/Alex/Downloads/Kaggle Data/train-jpg/train-jpg/\"\n",
    "test_path = \"/media/alex/B44254FE4254C730/Users/Alex/Downloads/Kaggle Data/test-jpg/\"\n",
    "\n",
    "train = pd.read_csv(\"/home/alex/Desktop/Rainforest/Data/train_v2.csv\")\n",
    "test =  pd.read_csv(\"/home/alex/Desktop/Rainforest/Data/sample_submission_v2.csv\")\n",
    "#Location for saving serialized objects\n",
    "obj_save_path = \"/home/alex/Desktop/Rainforest/Models/XGB/Objects/\"\n",
    "subm_output_path = \"/home/alex/Desktop/Rainforest/Submissions/\"\n",
    "print(\"------Paths Built-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Extraction Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Predefined Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features_PDF(df, data_path, name):\n",
    "    #Wrapper method to check for existence of extracted features.\n",
    "    \n",
    "    if(os.path.isfile(obj_save_path + 'PDF_Feature_Extraction_' + name + '.p')):\n",
    "        print('---- ' + 'Previous extraction found:' +'PDF_Feature_Extraction_' + name + '.p' +' ----' )\n",
    "        im_features = pickle.load(open(obj_save_path + 'PDF_Feature_Extraction_' + name + '.p','rb'))\n",
    "    else:\n",
    "        print('---- ' + 'Previous extraction NOT found:' +'PDF_Feature_Extraction_' + name + '.p' +' ----' )\n",
    "        print('---- ' + 'Extracting features' + ' ----')\n",
    "        im_features = _extract_featuresPDF(df, data_path, name)\n",
    "        pickle.dump(im_features, open(obj_save_path + 'PDF_Feature_Extraction_' + name + '.p','wb'))\n",
    "    \n",
    "    return im_features\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "def _extract_features_PDF(df, data_path, name):\n",
    "\t#create a copy of original panda dataframe so that extracted features can be added.\n",
    "\tim_features = df.copy()\n",
    "\tr_mean = []\n",
    "\tg_mean = []\n",
    "\tb_mean = []\n",
    "\n",
    "\tr_std=[]\n",
    "\tg_std=[]\n",
    "\tb_std=[]\n",
    "\n",
    "\tr_max=[]\n",
    "\tg_max=[]\n",
    "\tb_max=[]\n",
    "\t\n",
    "\tr_min=[]\n",
    "\tg_min=[]\n",
    "\tb_min=[]\n",
    "\n",
    "\tr_kurtosis=[]\n",
    "\tg_kurtosis=[]\n",
    "\tb_kurtosis=[]\n",
    "\n",
    "\tr_skewness=[]\n",
    "\tg_skewness=[]\n",
    "\tb_skewness=[]\n",
    "\n",
    "\tfor image_name in tqdm(im_features.image_name.values, miniters=1000):\n",
    "\t\t\n",
    "\t\tif \"file_\" in image_name:\n",
    "\t\t\tcontinue \n",
    "\t\tim = Image.open(data_path + image_name + '.jpg')\n",
    "\t\t#creating 256x256x3 array\n",
    "\t\tim= np.array(im)[:,:,:3]\n",
    "\t\t\n",
    "\t\t# im[:,:,0] has dimension 256x256; .ravel() flattens into 256^2 x 1\n",
    "\t\tr = im[:,:,0].ravel()\n",
    "\t\tg = im[:,:,1].ravel()\n",
    "\t\tb = im[:,:,2].ravel()\n",
    "\t\t\n",
    "\t\tr_mean.append(np.mean(r))\n",
    "\t\tg_mean.append(np.mean(g))\n",
    "\t\tb_mean.append(np.mean(b))\n",
    "\n",
    "\t\tr_std.append(np.std(r))\n",
    "\t\tg_std.append(np.std(g))\n",
    "\t\tb_std.append(np.std(b))\n",
    "\n",
    "\t\tr_max.append(np.max(r))\n",
    "\t\tg_max.append(np.max(g))\n",
    "\t\tb_max.append(np.max(b))\n",
    "\t\t\n",
    "\t\tr_min.append(np.min(r))\n",
    "\t\tg_min.append(np.min(g))\n",
    "\t\tb_min.append(np.min(b))\n",
    "\t\t\n",
    "\t\tr_kurtosis.append(scipy.stats.kurtosis(r))\n",
    "\t\tg_kurtosis.append(scipy.stats.kurtosis(g))\n",
    "\t\tb_kurtosis.append(scipy.stats.kurtosis(b))\n",
    "\t\t\n",
    "\t\tr_skewness.append(scipy.stats.skew(r))\n",
    "\t\tg_skewness.append(scipy.stats.skew(g))\n",
    "\t\tb_skewness.append(scipy.stats.skew(b))\n",
    "        \n",
    "        \n",
    "\n",
    "\t#Add extracted features to pandas frame\n",
    "\t#print(im_features['r_mean'].shape)\n",
    "\t#print(r_mean.shape)\n",
    "\tim_features['r_mean'] = r_mean\n",
    "\tim_features['g_mean'] = g_mean\n",
    "\tim_features['b_mean'] = b_mean\n",
    "\t\n",
    "\tim_features['r_std'] = r_std\n",
    "\tim_features['g_std'] = g_std\n",
    "\tim_features['b_std'] = b_std\n",
    "\t\n",
    "\tim_features['r_max'] = r_max\n",
    "\tim_features['g_max'] = g_max\n",
    "\tim_features['b_max'] = b_max\n",
    "\t\n",
    "\tim_features['r_min'] = r_min\n",
    "\tim_features['g_min'] = g_min\n",
    "\tim_features['b_min'] = b_min\n",
    "\t\n",
    "\tim_features['r_kurtosis'] = r_kurtosis\n",
    "\tim_features['g_kurtosis'] = g_kurtosis\n",
    "\tim_features['b_kurtosis'] = b_kurtosis\n",
    "\t\n",
    "\tim_features['r_skewness'] = r_skewness\n",
    "\tim_features['g_skewness'] = g_skewness\n",
    "\tim_features['b_skewness'] = b_skewness\n",
    "\t\n",
    "\t#return a pandas dataframe with above features extracted\n",
    "\treturn im_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: ResNet50 with top layer removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_features_RN50(df, data_path, name):\n",
    "    im_features = df.copy()\n",
    "    base_model = ResNet50(weights = 'imagenet', include_top = False)\n",
    "    \n",
    "    feats_all = None\n",
    "    #Attempt to resume\n",
    "    if(os.path.isfile(obj_save_path + 'RN50_feature_Extraction_' + name + '.p')):\n",
    "        print('----Previous Extraction found----')\n",
    "        file = open(obj_save_path + 'RN50_feature_Extraction_' + name + '.p','rb')\n",
    "        feats_all = pickle.load(file)\n",
    "        feats_all = np.array(feats_all)\n",
    "        file.close()\n",
    "        im_features = im_features[feats_all.shape[0]:]\n",
    "        print('----resuming at ' + str(feats_all.shape[0]) + ' ------')\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    i = 1\n",
    "    for image_name in tqdm(im_features.image_name.values, miniters=1000):\n",
    "        im = img_to_array(load_img(data_path + image_name + '.jpg', target_size=[224,224]))\n",
    "        im = np.expand_dims(im, axis=0)\n",
    "        feats = base_model.predict(im)\n",
    "        tmp = np.array(feats.ravel())\n",
    "        \n",
    "        if feats_all is None:\n",
    "            feats_all = tmp\n",
    "            \n",
    "        else:\n",
    "            feats_all = np.vstack((feats_all,tmp))\n",
    "            \n",
    "        if (i % 500) == 0:\n",
    "            print('-----Checkpoint at ' + str(i) + ' ------')\n",
    "            im_features = pd.DataFrame(feats_all)\n",
    "            pickle.dump(im_features, open(obj_save_path + 'RN50_feature_Extraction_' + name + '.p','wb'))\n",
    "            \n",
    "        i = i+1\n",
    "    \n",
    "    im_features = pd.DataFrame(feats_all)\n",
    "    pickle.dump(im_features, open(obj_save_path + 'RN50_feature_Extraction_' + name + '.p','wb'))\n",
    "    print('----' + name + ' Extraction complete--------')\n",
    "    return im_features\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Learning Methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#XGBoost:\n",
    "#Will add parameters to allow for tuning\n",
    "def _XGBoost(_X_train, _X_test, _y, _name):\n",
    "    y_pred_test = np.zeros((_X_test.shape[0], n_classes))\n",
    "    y_pred_train = np.zeros((_X_train.shape[0], n_classes))\n",
    "    \n",
    "    if os.path.isfile(obj_save_path + _name + '.p') and os.path.isfile(obj_save_path + _name +'train' + '.p'):\n",
    "        print('----' + _name + ' found ----')\n",
    "        y_pred_test = pickle.load(open(obj_save_path + _name + '.p','rb'))\n",
    "        y_pred_train = pickle.load(open(obj_save_path + _name + 'train'+ '.p','rb'))\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        print('----' + _name + 'not found: fitting XGB Model ----')\n",
    "        for class_i in tqdm( range(n_classes), miniters = 1 ):\n",
    "            model = xgb.XGBClassifier(max_depth=5, learning_rate=0.1, n_estimators=100, \\\n",
    "                                      silent=True, objective='binary:logistic', nthread=-1, \\\n",
    "                                      gamma=0, min_child_weight=1, max_delta_step=0, \\\n",
    "                                      subsample=1, colsample_bytree=1, colsample_bylevel=1, \\\n",
    "                                      reg_alpha=0, reg_lambda=1, scale_pos_weight=1, \\\n",
    "                                      base_score=0.5, seed=random_seed, missing=None)\n",
    "            model.fit(_X_train, _y[:, class_i])\n",
    "            #Apply model i\n",
    "            y_pred_test[:,class_i] = model.predict_proba(_X_test)[:,1]\n",
    "            y_pred_train[:,class_i] = model.predict_proba(_X_train)[:,1]\n",
    "    \n",
    "        pickle.dump(y_pred_test, open(obj_save_path + _name + '.p','wb'))\n",
    "        pickle.dump(y_pred_train, open(obj_save_path + _name +'train'+ '.p','wb'))\n",
    "    return list((y_pred_test, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50 (-1 layer) Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Previous Extraction found----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----resuming at 40479 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----train Extraction complete--------\n",
      "----Previous Extraction found----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----resuming at 40669 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----test Extraction complete--------\n"
     ]
    }
   ],
   "source": [
    "#Extract Features\n",
    "train_features = extract_features_RN50(train,train_path, 'train')\n",
    "\n",
    "test_features = extract_features_RN50(test,test_path,'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Check shapes----\n",
      "X: (40479, 2048)\n",
      "y: (40479, 17)\n",
      "X_test: (40669, 2048)\n",
      "Classes: 17\n",
      "----RN50_XGB_Pred found ----\n"
     ]
    }
   ],
   "source": [
    "#Prepare for XGBoost:\n",
    "X = np.array(train_features)\n",
    "X_test  = np.array(test_features)\n",
    "y = train['tags'].str.get_dummies(sep=' ')\n",
    "y = np.array(y, np.uint8)\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "tmp = []\n",
    "for l in train['tags'].values:\n",
    "    tmp.append(l.split(' '))\n",
    "    \n",
    "labels = np.array(list(set(flatten(tmp))))\n",
    "\n",
    "\n",
    "print('----Check shapes----')\n",
    "print('X: ' + str(X.shape))\n",
    "print('y: ' + str(y.shape))\n",
    "print('X_test: ' + str(X_test.shape))\n",
    "print('Classes: ' + str(n_classes))\n",
    "\n",
    "#Apply XGBoost:\n",
    "XGB_Ret = _XGBoost(X,X_test,y, 'RN50_XGB_Pred') \n",
    "y_pred_test = XGB_Ret[0]\n",
    "y_pred_train = XGB_Ret[1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_beta score:\n",
      "0.819351442538\n",
      "---- End ResNet50 Model----\n"
     ]
    }
   ],
   "source": [
    "#Define classification thresholds as column averages\n",
    "class_thresholds_train = np.zeros(17)\n",
    "class_thresholds_test = np.zeros(17)\n",
    "\n",
    "for col in range(y_pred_test.shape[1]):\n",
    "    class_thresholds_test[col] = np.average(y_pred_test[:,col])\n",
    "\n",
    "for col in range(y_pred_train.shape[1]):\n",
    "    class_thresholds_train[col] = np.average(y_pred_train[:,col])\n",
    "    \n",
    "\n",
    "#apply thresholds:\n",
    "y_pred_c_test = (y_pred_test > class_thresholds_test)*1.0\n",
    "y_pred_c_train = (y_pred_train > class_thresholds_train)*1.0\n",
    "\n",
    "#y_pred_c_test = (y_pred_test > 0.22222)*1.0\n",
    "#y_pred_c_train = (y_pred_train > 0.22222)*1.0\n",
    "\n",
    "#Return train score\n",
    "print('f_beta score:')\n",
    "print(fbeta_score(y,y_pred_c_train,beta=2, average='samples'))\n",
    "\n",
    "#Build submission\n",
    "labels = train['tags'].str.get_dummies(sep=' ').columns\n",
    "test_labels = []\n",
    "for row in range(y_pred_c_test.shape[0]):\n",
    "    test_labels.append(' '.join(labels[y_pred_c_test[row,:]==1]))\n",
    "Submission_RN50 = test.copy()\n",
    "Submission_RN50.drop('tags', axis = 1)\n",
    "Submission_RN50['tags'] = test_labels\n",
    "Submission_RN50.to_csv(str(subm_output_path + 'submission_RN50.csv'), index = False)\n",
    "print('---- End ResNet50 Model----')\n",
    "y = train['tags'].str.get_dummies(sep=' ')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-defined feature Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Previous extraction found:PDF_Feature_Extraction_train.p ----\n",
      "---- Previous extraction found:PDF_Feature_Extraction_test.p ----\n"
     ]
    }
   ],
   "source": [
    "#Pre-defined feature model = PDFModel\n",
    "PDFModel_train_features = extract_features_PDF(train, train_path, 'train')\n",
    "PDFModel_test_features = extract_features_PDF(test, test_path, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Check shapes----\n",
      "X: (40479, 18)\n",
      "y: (40479, 17)\n",
      "X_test: (40669, 18)\n",
      "Classes: 17\n",
      "----PDFModel_XGB_Prednot found: fitting XGB Model ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:38<00:00,  2.22s/it]\n"
     ]
    }
   ],
   "source": [
    "#Prepare for XGBoost:\n",
    "X = np.array(PDFModel_train_features.drop(['image_name', 'tags'],axis = 1))\n",
    "X_test  = np.array(PDFModel_test_features.drop(['image_name', 'tags'],axis = 1))\n",
    "y = train['tags'].str.get_dummies(sep=' ')\n",
    "\n",
    "y = np.array(y, np.uint8)\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "tmp = []\n",
    "for l in train['tags'].values:\n",
    "    tmp.append(l.split(' '))\n",
    "    \n",
    "labels = np.array(list(set(flatten(tmp))))\n",
    "\n",
    "print('----Check shapes----')\n",
    "print('X: ' + str(X.shape))\n",
    "print('y: ' + str(y.shape))\n",
    "print('X_test: ' + str(X_test.shape))\n",
    "print('Classes: ' + str(n_classes))\n",
    "\n",
    "#Apply XGBoost:\n",
    "XGB_Ret = _XGBoost(X,X_test,y, 'PDFModel_XGB_Pred') \n",
    "y_pred_test = XGB_Ret[0]\n",
    "y_pred_train = XGB_Ret[1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_beta score:\n",
      "0.905139358748\n",
      "---- End ResNet50 Model----\n"
     ]
    }
   ],
   "source": [
    "#Define classification thresholds as column averages\n",
    "class_thresholds_train = np.zeros(17)\n",
    "class_thresholds_test = np.zeros(17)\n",
    "\n",
    "for col in range(y_pred_test.shape[1]):\n",
    "    class_thresholds_test[col] = np.average(y_pred_test[:,col])\n",
    "\n",
    "for col in range(y_pred_train.shape[1]):\n",
    "    class_thresholds_train[col] = np.average(y_pred_train[:,col])\n",
    "\n",
    "#apply thresholds:\n",
    "#y_pred_c_test = (y_pred_test > class_thresholds_test)*1.0\n",
    "#y_pred_c_train = (y_pred_train > class_thresholds_train)*1.0\n",
    "\n",
    "y_pred_c_test = (y_pred_test > .2222222)*1.0\n",
    "y_pred_c_train = (y_pred_train > .222222)*1.0\n",
    "\n",
    "\n",
    "#Return train score\n",
    "print('f_beta score:')\n",
    "print(fbeta_score(y,y_pred_c_train,beta=2, average='samples'))\n",
    "\n",
    "#Build submission\n",
    "labels = train['tags'].str.get_dummies(sep=' ').columns\n",
    "test_labels = []\n",
    "for row in range(y_pred_c_test.shape[0]):\n",
    "    test_labels.append(' '.join(labels[y_pred_c_test[row,:]==1]))\n",
    "Submission_PDFModel = test.copy()\n",
    "Submission_PDFModel.drop('tags', axis = 1)\n",
    "Submission_PDFModel['tags'] = test_labels\n",
    "Submission_PDFModel.to_csv(str(subm_output_path + 'submission_PDFModel.csv'), index = False)\n",
    "print('---- End ResNet50 Model----')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.30430032,  0.00842468,  0.02131553,  0.00825091,  0.00244761,\n",
       "        0.70233841,  0.05164864,  0.00248333,  0.11067056,  0.09048466,\n",
       "        0.06665388,  0.17947589,  0.92670635,  0.19945985,  0.00844782,\n",
       "        0.00517558,  0.18303542])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_thresholds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16776805025407501"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(class_thresholds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold Tuning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.4836858915\n",
      "----\n",
      "0.010101010101\n",
      "0.740317510686\n",
      "----\n",
      "0.020202020202\n",
      "0.789891231724\n",
      "----\n",
      "0.030303030303\n",
      "0.819730410699\n",
      "----\n",
      "0.040404040404\n",
      "0.835879451995\n",
      "----\n",
      "0.0505050505051\n",
      "0.847709337374\n",
      "----\n",
      "0.0606060606061\n",
      "0.856824235621\n",
      "----\n",
      "0.0707070707071\n",
      "0.864028228468\n",
      "----\n",
      "0.0808080808081\n",
      "0.870154321625\n",
      "----\n",
      "0.0909090909091\n",
      "0.875287923792\n",
      "----\n",
      "0.10101010101\n",
      "0.880139391838\n",
      "----\n",
      "0.111111111111\n",
      "0.884156517544\n",
      "----\n",
      "0.121212121212\n",
      "0.88781175259\n",
      "----\n",
      "0.131313131313\n",
      "0.891144796393\n",
      "----\n",
      "0.141414141414\n",
      "0.894142614139\n",
      "----\n",
      "0.151515151515\n",
      "0.896493518004\n",
      "----\n",
      "0.161616161616\n",
      "0.898336970631\n",
      "----\n",
      "0.171717171717\n",
      "0.90020124565\n",
      "----\n",
      "0.181818181818\n",
      "0.901987759249\n",
      "----\n",
      "0.191919191919\n",
      "0.903262491892\n",
      "----\n",
      "0.20202020202\n",
      "0.904156946317\n",
      "----\n",
      "0.212121212121\n",
      "0.904887616763\n",
      "----\n",
      "0.222222222222\n",
      "0.905139358748\n",
      "----\n",
      "0.232323232323\n",
      "0.905073142298\n",
      "----\n",
      "0.242424242424\n",
      "0.905070027506\n",
      "----\n",
      "0.252525252525\n",
      "0.904636801782\n",
      "----\n",
      "0.262626262626\n",
      "0.903814320046\n",
      "----\n",
      "0.272727272727\n",
      "0.902935793507\n",
      "----\n",
      "0.282828282828\n",
      "0.901829114711\n",
      "----\n",
      "0.292929292929\n",
      "0.90060956346\n",
      "----\n",
      "0.30303030303\n",
      "0.899158950063\n",
      "----\n",
      "0.313131313131\n",
      "0.89762304305\n",
      "----\n",
      "0.323232323232\n",
      "0.895854966662\n",
      "----\n",
      "0.333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/NeuralNetworks/keras_tf/lib/python3.4/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.894195971651\n",
      "----\n",
      "0.343434343434\n",
      "0.892121884461\n",
      "----\n",
      "0.353535353535\n",
      "0.890332731516\n",
      "----\n",
      "0.363636363636\n",
      "0.88844288647\n",
      "----\n",
      "0.373737373737\n",
      "0.886095842565\n",
      "----\n",
      "0.383838383838\n",
      "0.884125165324\n",
      "----\n",
      "0.393939393939\n",
      "0.882319190919\n",
      "----\n",
      "0.40404040404\n",
      "0.880081887039\n",
      "----\n",
      "0.414141414141\n",
      "0.878152415357\n",
      "----\n",
      "0.424242424242\n",
      "0.875820275184\n",
      "----\n",
      "0.434343434343\n",
      "0.873468777831\n",
      "----\n",
      "0.444444444444\n",
      "0.871073517376\n",
      "----\n",
      "0.454545454545\n",
      "0.86870383496\n",
      "----\n",
      "0.464646464646\n",
      "0.866066079789\n",
      "----\n",
      "0.474747474747\n",
      "0.863446904088\n",
      "----\n",
      "0.484848484848\n",
      "0.861017590234\n",
      "----\n",
      "0.494949494949\n",
      "0.858271409092\n",
      "----\n",
      "0.505050505051\n",
      "0.855672605492\n",
      "----\n",
      "0.515151515152\n",
      "0.853063585479\n",
      "----\n",
      "0.525252525253\n",
      "0.849939681127\n",
      "----\n",
      "0.535353535354\n",
      "0.847235330727\n",
      "----\n",
      "0.545454545455\n",
      "0.844113135272\n",
      "----\n",
      "0.555555555556\n",
      "0.840995805985\n",
      "----\n",
      "0.565656565657\n",
      "0.838010860741\n",
      "----\n",
      "0.575757575758\n",
      "0.834985826571\n",
      "----\n",
      "0.585858585859\n",
      "0.831585862331\n",
      "----\n",
      "0.59595959596\n",
      "0.828094257815\n",
      "----\n",
      "0.606060606061\n",
      "0.824799332671\n",
      "----\n",
      "0.616161616162\n",
      "0.821320717972\n",
      "----\n",
      "0.626262626263\n",
      "0.817423623699\n",
      "----\n",
      "0.636363636364\n",
      "0.813726091678\n",
      "----\n",
      "0.646464646465\n",
      "0.809868079629\n",
      "----\n",
      "0.656565656566\n",
      "0.806000983982\n",
      "----\n",
      "0.666666666667\n",
      "0.802041232467\n",
      "----\n",
      "0.676767676768\n",
      "0.797965536234\n",
      "----\n",
      "0.686868686869\n",
      "0.793884581632\n",
      "----\n",
      "0.69696969697\n",
      "0.789897122768\n",
      "----\n",
      "0.707070707071\n",
      "0.785421969536\n",
      "----\n",
      "0.717171717172\n",
      "0.78067557168\n",
      "----\n",
      "0.727272727273\n",
      "0.775817497597\n",
      "----\n",
      "0.737373737374\n",
      "0.77120426114\n",
      "----\n",
      "0.747474747475\n",
      "0.766359471253\n",
      "----\n",
      "0.757575757576\n",
      "0.76109066274\n",
      "----\n",
      "0.767676767677\n",
      "0.755889235363\n",
      "----\n",
      "0.777777777778\n",
      "0.750172048144\n",
      "----\n",
      "0.787878787879\n",
      "0.74428234957\n",
      "----\n",
      "0.79797979798\n",
      "0.738423319893\n",
      "----\n",
      "0.808080808081\n",
      "0.731993798783\n",
      "----\n",
      "0.818181818182\n",
      "0.725160449726\n",
      "----\n",
      "0.828282828283\n",
      "0.717951588202\n",
      "----\n",
      "0.838383838384\n",
      "0.710516397556\n",
      "----\n",
      "0.848484848485\n",
      "0.701924810207\n",
      "----\n",
      "0.858585858586\n",
      "0.693150490063\n",
      "----\n",
      "0.868686868687\n",
      "0.683526721313\n",
      "----\n",
      "0.878787878788\n",
      "0.673091616417\n",
      "----\n",
      "0.888888888889\n",
      "0.661960673582\n",
      "----\n",
      "0.89898989899\n",
      "0.650325248085\n",
      "----\n",
      "0.909090909091\n",
      "0.637787840002\n",
      "----\n",
      "0.919191919192\n",
      "0.624474137051\n",
      "----\n",
      "0.929292929293\n",
      "0.610460890723\n",
      "----\n",
      "0.939393939394\n",
      "0.594259318693\n",
      "----\n",
      "0.949494949495\n",
      "0.576095814561\n",
      "----\n",
      "0.959595959596\n",
      "0.554618954871\n",
      "----\n",
      "0.969696969697\n",
      "0.526850726641\n",
      "----\n",
      "0.979797979798\n",
      "0.49162149585\n",
      "----\n",
      "0.989898989899\n",
      "0.437571100687\n",
      "----\n",
      "1.0\n",
      "0.0\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "t = np.linspace(0,1,num = 100)\n",
    "\n",
    "for a in t:\n",
    "    y_pred_c_train = (y_pred_train > a)*1.0\n",
    "    print(a)\n",
    "    print(fbeta_score(y,y_pred_c_train,beta=2, average='samples'))\n",
    "    print('----')\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "my-keras_tf",
   "language": "python",
   "name": "my-keras_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
